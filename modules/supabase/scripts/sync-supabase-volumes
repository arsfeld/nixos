#!/usr/bin/env bash
set -euo pipefail

# Script to sync Supabase docker/volumes files from GitHub
# This ensures we have all the latest configuration files from upstream

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TARGET_DIR="${SCRIPT_DIR}/../files/volumes"
GITHUB_BASE_URL="https://raw.githubusercontent.com/supabase/supabase/master/docker/volumes"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}Syncing Supabase docker/volumes files from GitHub...${NC}"

# Create target directory if it doesn't exist
mkdir -p "$TARGET_DIR"

# Function to download a file
download_file() {
    local relative_path="$1"
    local target_path="${TARGET_DIR}/${relative_path}"
    local source_url="${GITHUB_BASE_URL}/${relative_path}"
    
    # Create directory if needed
    mkdir -p "$(dirname "$target_path")"
    
    echo -e "${YELLOW}Downloading: ${relative_path}${NC}"
    if curl -sL -o "$target_path" "$source_url"; then
        # Check if we got a 404 error page
        if grep -q "404: Not Found" "$target_path" 2>/dev/null; then
            echo -e "${RED}  ✗ File not found: ${relative_path}${NC}"
            rm -f "$target_path"
            return 1
        else
            echo -e "${GREEN}  ✓ Downloaded: ${relative_path}${NC}"
            return 0
        fi
    else
        echo -e "${RED}  ✗ Failed to download: ${relative_path}${NC}"
        return 1
    fi
}

# Download volumes directory structure
# First, get the directory listing from GitHub API
echo -e "\n${YELLOW}Fetching directory structure from GitHub API...${NC}"

# Function to recursively download files from a directory
download_directory() {
    local dir_path="$1"
    local api_url="https://api.github.com/repos/supabase/supabase/contents/docker/volumes${dir_path:+/$dir_path}"
    
    echo -e "${YELLOW}Scanning directory: ${dir_path:-/}${NC}"
    
    # Get directory contents via GitHub API
    local response=$(curl -sL "$api_url")
    
    # Check if we got a valid response
    if echo "$response" | grep -q '"message".*"Not Found"'; then
        echo -e "${RED}Directory not found: ${dir_path}${NC}"
        return 1
    fi
    
    # Parse JSON response and download files
    echo "$response" | grep -E '"(name|type|path)"' | sed 's/.*": "\(.*\)".*/\1/' | \
    while read -r name && read -r path && read -r type; do
        if [ "$type" = "file" ]; then
            # Remove docker/volumes/ prefix from path
            local relative_path="${path#docker/volumes/}"
            download_file "$relative_path"
        elif [ "$type" = "dir" ]; then
            # Recursively download directory contents
            local subdir="${path#docker/volumes/}"
            download_directory "$subdir"
        fi
    done
}

# Known directories in docker/volumes based on typical Supabase structure
KNOWN_DIRS=(
    "api"
    "db"
    "functions"
    "logs"
    "storage"
)

# Download files from each known directory
for dir in "${KNOWN_DIRS[@]}"; do
    echo -e "\n${GREEN}Processing ${dir} directory...${NC}"
    download_directory "$dir"
done

# Also check for any files in the root volumes directory
echo -e "\n${GREEN}Checking for files in volumes root...${NC}"
download_directory ""

# Special case: Download known important files that might not show up in API
echo -e "\n${GREEN}Downloading known configuration files...${NC}"

KNOWN_FILES=(
    "db/init/data.sql"
    "db/jwt.sql"
    "db/logs.sql"
    "db/pooler.sql"
    "db/realtime.sql"
    "db/roles.sql"
    "db/webhooks.sql"
    "db/_supabase.sql"
    "functions/hello/index.ts"
    "functions/main/index.ts"
    "api/kong.yml"
    "logs/vector.yml"
)

for file in "${KNOWN_FILES[@]}"; do
    download_file "$file"
done

echo -e "\n${GREEN}Sync complete!${NC}"
echo -e "${YELLOW}Files synced to: ${TARGET_DIR}${NC}"

# List what we downloaded
echo -e "\n${GREEN}Downloaded structure:${NC}"
find "$TARGET_DIR" -type f | sort | sed "s|$TARGET_DIR/|  |"